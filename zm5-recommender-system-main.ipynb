{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEAM ZM5\n",
    "\n",
    "# EDSA MOVIE RECOMMENDATION CHALLENGE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing packages\n",
    "Please download all relevant packages in. There is no terminal so you will need to pip install everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import comet_ml at the top of your file\n",
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment with your api key for version control\n",
    "experiment = Experiment(\n",
    "    api_key=\"amGQj1TC3Wyk9LYf7bD9xNV6G\",\n",
    "    project_name=\"movie-reccomender-edsa\",\n",
    "    workspace=\"daniel-bru\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:04:16.308512Z",
     "iopub.status.busy": "2021-07-06T13:04:16.30824Z",
     "iopub.status.idle": "2021-07-06T13:04:17.518703Z",
     "shell.execute_reply": "2021-07-06T13:04:17.51797Z",
     "shell.execute_reply.started": "2021-07-06T13:04:16.308485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install packages here\n",
    "# Packages for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as sp\n",
    "\n",
    "# Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Packages for modeling\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "import heapq\n",
    "\n",
    "# Packages for model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from time import time\n",
    "\n",
    "# Package to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Packages for saving models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:04:50.227583Z",
     "iopub.status.busy": "2021-07-06T13:04:50.226968Z",
     "iopub.status.idle": "2021-07-06T13:05:14.365789Z",
     "shell.execute_reply": "2021-07-06T13:05:14.364978Z",
     "shell.execute_reply.started": "2021-07-06T13:04:50.227544Z"
    }
   },
   "outputs": [],
   "source": [
    "root_path = ''\n",
    "df_sample_submission = pd.read_csv(root_path + 'sample_submission.csv')\n",
    "df_movies = pd.read_csv(root_path + 'movies.csv')\n",
    "df_imdb = pd.read_csv(root_path + 'imdb_data.csv')\n",
    "df_genome_scores = pd.read_csv(root_path + 'genome_scores.csv')\n",
    "df_genome_tags = pd.read_csv(root_path +'genome_tags.csv')\n",
    "df_train = pd.read_csv(root_path + 'train.csv')\n",
    "df_test = pd.read_csv(root_path + 'test.csv')\n",
    "df_tags = pd.read_csv(root_path + 'tags.csv')\n",
    "df_links = pd.read_csv(root_path + 'links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max.column\", None)\n",
    "print(df_sample_submission.info())\n",
    "df_sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:05:21.664773Z",
     "iopub.status.busy": "2021-07-06T13:05:21.662618Z",
     "iopub.status.idle": "2021-07-06T13:05:21.692604Z",
     "shell.execute_reply": "2021-07-06T13:05:21.691797Z",
     "shell.execute_reply.started": "2021-07-06T13:05:21.664733Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_movies.info())\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_imdb.info())\n",
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_genome_scores.info())\n",
    "df_genome_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_genome_tags.info())\n",
    "df_genome_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tags.info())\n",
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_links.info())\n",
    "df_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:06:25.092732Z",
     "iopub.status.busy": "2021-07-06T13:06:25.092142Z",
     "iopub.status.idle": "2021-07-06T13:06:25.104808Z",
     "shell.execute_reply": "2021-07-06T13:06:25.103788Z",
     "shell.execute_reply.started": "2021-07-06T13:06:25.092686Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_train.info())\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test.info())\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most common Genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:06:37.24618Z",
     "iopub.status.busy": "2021-07-06T13:06:37.245633Z",
     "iopub.status.idle": "2021-07-06T13:06:37.573854Z",
     "shell.execute_reply": "2021-07-06T13:06:37.572951Z",
     "shell.execute_reply.started": "2021-07-06T13:06:37.246133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataframe containing only the movieId and genres\n",
    "movies_genres = pd.DataFrame(df_movies[['movieId', 'genres']],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "# Split genres seperated by \"|\" and create a list containing the genres allocated to each movie\n",
    "movies_genres.genres = movies_genres.genres.apply(lambda x: x.split('|'))\n",
    "\n",
    "# Create expanded dataframe where each movie-genre combination is in a seperate row\n",
    "movies_genres = pd.DataFrame([(tup.movieId, d) for tup in movies_genres.itertuples() for d in tup.genres],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "movies_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:06:38.927964Z",
     "iopub.status.busy": "2021-07-06T13:06:38.927603Z",
     "iopub.status.idle": "2021-07-06T13:06:39.37779Z",
     "shell.execute_reply": "2021-07-06T13:06:39.376846Z",
     "shell.execute_reply.started": "2021-07-06T13:06:38.92793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the genres from most common to least common\n",
    "plot = plt.figure(figsize=(15, 10))\n",
    "plt.title('Most common genres\\n', fontsize=20)\n",
    "sns.countplot(y=\"genres\", data=movies_genres,\n",
    "              order=movies_genres['genres'].value_counts(ascending=False).index,\n",
    "              palette='Reds_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepartion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-06T09:47:42.880955Z",
     "iopub.status.busy": "2021-06-06T09:47:42.880465Z",
     "iopub.status.idle": "2021-06-06T09:47:42.885223Z",
     "shell.execute_reply": "2021-06-06T09:47:42.88448Z",
     "shell.execute_reply.started": "2021-06-06T09:47:42.880914Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings = df_train.copy()\n",
    "ratings_dict = {'itemID': list(ratings.movieId),\n",
    "                'userID': list(ratings.userId),\n",
    "                'rating': list(ratings.rating)}\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainset, testset = train_test_split(data, test_size=.01)\n",
    "\n",
    "algo = SVD()\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Compute RMSE\n",
    "accuracy.rmse(predictions)  # RMSE: 0.8165    11min 28s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create Submission\n",
    "Hit the blue Publish button at the top of your notebook screen. It will take some time for your kernel to run. When it has finished your navigation bar at the top of the screen will have a tab for Output. This only shows up if you have written an output file (like we did in the Prepare Submission File step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(algo, save_name):\n",
    "    \n",
    "    ratings_predictions = [algo.predict(row.userId, row.movieId) for _,row in df_test.iterrows()]\n",
    "    df_pred = pd.DataFrame(ratings_predictions)\n",
    "    df_pred = df_pred.rename(columns={'uid':'userId', 'iid':'movieId','est':'rating'})\n",
    "    df_pred.drop(['r_ui','details'],axis=1,inplace=True)\n",
    "    # Create ID column\n",
    "    df_pred['Id'] = df_pred.apply(lambda x:'%s_%s' % (x['userId'],x['movieId']),axis=1)\n",
    "    df_pred['Id'] = df_pred.apply(lambda x:'%s_%s' % (x['userId'],x['movieId']),axis=1)\n",
    "    df_pred = df_pred[['Id', 'rating']]\n",
    "    df_pred.to_csv(save_name + '.csv', index=False)\n",
    "    \n",
    "    return pd.read_csv('./' + save_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = create_submission(algo, 'SVD_01')\n",
    "submission.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle The Model\n",
    "model_save_path = \"SVD_1.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(algo,file)\n",
    "\n",
    "# Create Download Link and use google collab to save in Google Drive because file size is pretty large\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'./SVD_1.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
